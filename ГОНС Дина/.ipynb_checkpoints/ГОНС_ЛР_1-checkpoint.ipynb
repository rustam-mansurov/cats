{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6ZTFl0Srvr_"
      },
      "source": [
        "##ГЛУБИННОЕ ОБУЧЕНИЕ НЕЙРОННЫХ СЕТЕЙ\n",
        "##ЛАБОРАТОРНАЯ РАБОТА №1\n",
        "М21-181-1 Перевощикова Дина Александровна\n",
        "\n",
        "Основы работы с фреймворками TensorFlow/Keras\n",
        "\n",
        "Цель работы – научиться реализовывать нейронные сети во фреймворке\n",
        "TensorFlow/Keras для решения задач классификации данных и распознавания\n",
        "изображений с использованием предобученных нейронных сетей из\n",
        "стандартного набора данных.\n",
        "\n",
        "Задачи:\n",
        "1. Научиться устанавливать фреймворк TensorFlow/Keras и изучить\n",
        "возможности реализации нейронных сетей для классификации данных.\n",
        "2. Получить навыки создания нейронных сетей глубокого обучения для\n",
        "распознавания изображений из стандартных наборов данных.\n",
        "3. Исследовать обобщающую способность нейронных сетей в зависимости от\n",
        "числа итераций обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZoYqwJ8wJ2G"
      },
      "source": [
        "## Загрузка и предобработка статистических данных в TensorFlow/Keras\n",
        "Для примера используем набор данных iris.csv. Для работы с набором данных добавим некоторые библиотеки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hgeN9Y6NUaJc"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VabMXfvwbQ2"
      },
      "source": [
        "Разделим выборку iris.csv на тренировочную и тестовую"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/Iris.csv', sep = ',')\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "Y = data['Species']\n",
        "X = data.drop(['Id', 'Species'], axis=1)\n",
        "print(\"Shape of Input  features: {}\".format(X.shape))\n",
        "print(\"Shape of Output features: {}\".format(Y.shape))\n",
        "Y.value_counts()\n",
        "lbl_clf = LabelEncoder()\n",
        "Y_encoded = lbl_clf.fit_transform(Y)\n",
        "\n",
        "#Keras requires your output feature to be one-hot encoded values.\n",
        "Y_final = tf.keras.utils.to_categorical(Y_encoded)\n",
        "\n",
        "print(\"Therefore, our final shape of output feature will be {}\".format(Y_final.shape))\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y_final, test_size=0.25, random_state=seed, stratify=Y_encoded, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suh8mTlDigcI",
        "outputId": "0cd0adc3-8056-41b4-f1f4-9d4a7898f305"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Input  features: (150, 4)\n",
            "Shape of Output features: (150,)\n",
            "Therefore, our final shape of output feature will be (150, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v7wF-BpUMgxZ",
        "outputId": "9063f8aa-76d5-42a9-e9d4-6c8bfcd34736"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1d2f428-b778-4cfa-b838-f1ad8ade9620\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1d2f428-b778-4cfa-b838-f1ad8ade9620')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1d2f428-b778-4cfa-b838-f1ad8ade9620 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1d2f428-b778-4cfa-b838-f1ad8ade9620');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std_clf = StandardScaler()\n",
        "x_train_new = std_clf.fit_transform(x_train)\n",
        "x_test_new = std_clf.transform(x_test)"
      ],
      "metadata": {
        "id": "JXBLAyADisvE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, input_dim=4, activation=tf.nn.relu, kernel_initializer='he_normal', \n",
        "                                kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(7, activation=tf.nn.relu, kernel_initializer='he_normal', \n",
        "                                kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(5, activation=tf.nn.relu, kernel_initializer='he_normal', \n",
        "                                kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
        "model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "iris_model = model.fit(x_train_new, y_train, epochs=700, batch_size=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C63bwUZiuj8",
        "outputId": "4b42e1d3-68a2-4b3d-e1a1-2b8dd6162877"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "16/16 [==============================] - 6s 12ms/step - loss: 1.3999 - accuracy: 0.2679\n",
            "Epoch 2/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.4859 - accuracy: 0.2411\n",
            "Epoch 3/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.3508 - accuracy: 0.3036\n",
            "Epoch 4/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.3213 - accuracy: 0.3929\n",
            "Epoch 5/700\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 1.3126 - accuracy: 0.3750\n",
            "Epoch 6/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.2691 - accuracy: 0.4107\n",
            "Epoch 7/700\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.2706 - accuracy: 0.4464\n",
            "Epoch 8/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.2177 - accuracy: 0.4643\n",
            "Epoch 9/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.2083 - accuracy: 0.5357\n",
            "Epoch 10/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.2261 - accuracy: 0.4911\n",
            "Epoch 11/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1906 - accuracy: 0.5179\n",
            "Epoch 12/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.2043 - accuracy: 0.5179\n",
            "Epoch 13/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.1093 - accuracy: 0.6161\n",
            "Epoch 14/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1456 - accuracy: 0.6071\n",
            "Epoch 15/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.1408 - accuracy: 0.5714\n",
            "Epoch 16/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1354 - accuracy: 0.5893\n",
            "Epoch 17/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.1110 - accuracy: 0.6875\n",
            "Epoch 18/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1.0389 - accuracy: 0.7054\n",
            "Epoch 19/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.9502 - accuracy: 0.7679\n",
            "Epoch 20/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0213 - accuracy: 0.7321\n",
            "Epoch 21/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.9461 - accuracy: 0.7411\n",
            "Epoch 22/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.9779 - accuracy: 0.7411\n",
            "Epoch 23/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.0126 - accuracy: 0.7411\n",
            "Epoch 24/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.9363 - accuracy: 0.7500\n",
            "Epoch 25/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.9403 - accuracy: 0.7321\n",
            "Epoch 26/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.9586 - accuracy: 0.7589\n",
            "Epoch 27/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.9122 - accuracy: 0.7054\n",
            "Epoch 28/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1.0215 - accuracy: 0.6696\n",
            "Epoch 29/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8353 - accuracy: 0.7946\n",
            "Epoch 30/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8532 - accuracy: 0.7589\n",
            "Epoch 31/700\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.9709 - accuracy: 0.7232\n",
            "Epoch 32/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8941 - accuracy: 0.7589\n",
            "Epoch 33/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7689 - accuracy: 0.8214\n",
            "Epoch 34/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8989 - accuracy: 0.7500\n",
            "Epoch 35/700\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.8300 - accuracy: 0.8036\n",
            "Epoch 36/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7282 - accuracy: 0.8036\n",
            "Epoch 37/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.8094 - accuracy: 0.7857\n",
            "Epoch 38/700\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.8735 - accuracy: 0.7589\n",
            "Epoch 39/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8141 - accuracy: 0.7679\n",
            "Epoch 40/700\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.7818 - accuracy: 0.7768\n",
            "Epoch 41/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7632 - accuracy: 0.8214\n",
            "Epoch 42/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7431 - accuracy: 0.8393\n",
            "Epoch 43/700\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7377 - accuracy: 0.8036\n",
            "Epoch 44/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.8069 - accuracy: 0.7679\n",
            "Epoch 45/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6943 - accuracy: 0.8571\n",
            "Epoch 46/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7789 - accuracy: 0.7768\n",
            "Epoch 47/700\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.8482\n",
            "Epoch 48/700\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.6306 - accuracy: 0.8393\n",
            "Epoch 49/700\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.6775 - accuracy: 0.8214\n",
            "Epoch 50/700\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.6062 - accuracy: 0.8839\n",
            "Epoch 51/700\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.6044 - accuracy: 0.8750\n",
            "Epoch 52/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7652 - accuracy: 0.8036\n",
            "Epoch 53/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7437 - accuracy: 0.8482\n",
            "Epoch 54/700\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.8214\n",
            "Epoch 55/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5774 - accuracy: 0.8482\n",
            "Epoch 56/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.6701 - accuracy: 0.8482\n",
            "Epoch 57/700\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.6735 - accuracy: 0.8661\n",
            "Epoch 58/700\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.5485 - accuracy: 0.8750\n",
            "Epoch 59/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7254 - accuracy: 0.7857\n",
            "Epoch 60/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.6671 - accuracy: 0.8214\n",
            "Epoch 61/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5366 - accuracy: 0.8661\n",
            "Epoch 62/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.6236 - accuracy: 0.8393\n",
            "Epoch 63/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.8839\n",
            "Epoch 64/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.8929\n",
            "Epoch 65/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5050 - accuracy: 0.9018\n",
            "Epoch 66/700\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6096 - accuracy: 0.8214\n",
            "Epoch 67/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.8929\n",
            "Epoch 68/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7040 - accuracy: 0.8125\n",
            "Epoch 69/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5762 - accuracy: 0.8393\n",
            "Epoch 70/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5945 - accuracy: 0.8839\n",
            "Epoch 71/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7277 - accuracy: 0.7946\n",
            "Epoch 72/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5501 - accuracy: 0.8839\n",
            "Epoch 73/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.9018\n",
            "Epoch 74/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7061 - accuracy: 0.7857\n",
            "Epoch 75/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5332 - accuracy: 0.8661\n",
            "Epoch 76/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.9107\n",
            "Epoch 77/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.8929\n",
            "Epoch 78/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6456 - accuracy: 0.8571\n",
            "Epoch 79/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.8929\n",
            "Epoch 80/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.8929\n",
            "Epoch 81/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6618 - accuracy: 0.7857\n",
            "Epoch 82/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8270 - accuracy: 0.7679\n",
            "Epoch 83/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.8571\n",
            "Epoch 84/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.8750\n",
            "Epoch 85/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.9018\n",
            "Epoch 86/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.8750\n",
            "Epoch 87/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.8571\n",
            "Epoch 88/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.8036\n",
            "Epoch 89/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.8304\n",
            "Epoch 90/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.8839\n",
            "Epoch 91/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5107 - accuracy: 0.8750\n",
            "Epoch 92/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.9196\n",
            "Epoch 93/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.8661\n",
            "Epoch 94/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.8839\n",
            "Epoch 95/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6007 - accuracy: 0.8571\n",
            "Epoch 96/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.7946\n",
            "Epoch 97/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.9018\n",
            "Epoch 98/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.8839\n",
            "Epoch 99/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.8750\n",
            "Epoch 100/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.8839\n",
            "Epoch 101/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.8839\n",
            "Epoch 102/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.8839\n",
            "Epoch 103/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4411 - accuracy: 0.9018\n",
            "Epoch 104/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5957 - accuracy: 0.8304\n",
            "Epoch 105/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8929\n",
            "Epoch 106/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.8929\n",
            "Epoch 107/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.9018\n",
            "Epoch 108/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4671 - accuracy: 0.8571\n",
            "Epoch 109/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4775 - accuracy: 0.8750\n",
            "Epoch 110/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.9286\n",
            "Epoch 111/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.8750\n",
            "Epoch 112/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.8661\n",
            "Epoch 113/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.8839\n",
            "Epoch 114/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.8839\n",
            "Epoch 115/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8929\n",
            "Epoch 116/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5986 - accuracy: 0.8214\n",
            "Epoch 117/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.9286\n",
            "Epoch 118/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.8929\n",
            "Epoch 119/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.9196\n",
            "Epoch 120/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.8750\n",
            "Epoch 121/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.9107\n",
            "Epoch 122/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.8482\n",
            "Epoch 123/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.9286\n",
            "Epoch 124/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5709 - accuracy: 0.8304\n",
            "Epoch 125/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5536 - accuracy: 0.8214\n",
            "Epoch 126/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.8750\n",
            "Epoch 127/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.8839\n",
            "Epoch 128/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5786 - accuracy: 0.8661\n",
            "Epoch 129/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.9018\n",
            "Epoch 130/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.9018\n",
            "Epoch 131/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6102 - accuracy: 0.7857\n",
            "Epoch 132/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.8750\n",
            "Epoch 133/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.9107\n",
            "Epoch 134/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.8661\n",
            "Epoch 135/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.8839\n",
            "Epoch 136/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.8839\n",
            "Epoch 137/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5725 - accuracy: 0.8750\n",
            "Epoch 138/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4310 - accuracy: 0.9018\n",
            "Epoch 139/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3281 - accuracy: 0.9375\n",
            "Epoch 140/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4326 - accuracy: 0.9107\n",
            "Epoch 141/700\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.6021 - accuracy: 0.8304\n",
            "Epoch 142/700\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4711 - accuracy: 0.8750\n",
            "Epoch 143/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5565 - accuracy: 0.8393\n",
            "Epoch 144/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4445 - accuracy: 0.8929\n",
            "Epoch 145/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.9196\n",
            "Epoch 146/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4537 - accuracy: 0.8750\n",
            "Epoch 147/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.9286\n",
            "Epoch 148/700\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4136 - accuracy: 0.8929\n",
            "Epoch 149/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5376 - accuracy: 0.8750\n",
            "Epoch 150/700\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4354 - accuracy: 0.9196\n",
            "Epoch 151/700\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3548 - accuracy: 0.8929\n",
            "Epoch 152/700\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4331 - accuracy: 0.8929\n",
            "Epoch 153/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.8571\n",
            "Epoch 154/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.9018\n",
            "Epoch 155/700\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4492 - accuracy: 0.8929\n",
            "Epoch 156/700\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3950 - accuracy: 0.8839\n",
            "Epoch 157/700\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.4484 - accuracy: 0.8750\n",
            "Epoch 158/700\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3383 - accuracy: 0.9018\n",
            "Epoch 159/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3681 - accuracy: 0.9018\n",
            "Epoch 160/700\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4324 - accuracy: 0.9196\n",
            "Epoch 161/700\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.5140 - accuracy: 0.8482\n",
            "Epoch 162/700\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4343 - accuracy: 0.8750\n",
            "Epoch 163/700\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4395 - accuracy: 0.8661\n",
            "Epoch 164/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8661\n",
            "Epoch 165/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.9018\n",
            "Epoch 166/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.9018\n",
            "Epoch 167/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.9196\n",
            "Epoch 168/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4370 - accuracy: 0.8929\n",
            "Epoch 169/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.8750\n",
            "Epoch 170/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.8482\n",
            "Epoch 171/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5679 - accuracy: 0.8304\n",
            "Epoch 172/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.9196\n",
            "Epoch 173/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4544 - accuracy: 0.8929\n",
            "Epoch 174/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.8839\n",
            "Epoch 175/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.8929\n",
            "Epoch 176/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8750\n",
            "Epoch 177/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.8393\n",
            "Epoch 178/700\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.9107\n",
            "Epoch 179/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3736 - accuracy: 0.8929\n",
            "Epoch 180/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5764 - accuracy: 0.8214\n",
            "Epoch 181/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.8750\n",
            "Epoch 182/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8929\n",
            "Epoch 183/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4902 - accuracy: 0.8661\n",
            "Epoch 184/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.8571\n",
            "Epoch 185/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8929\n",
            "Epoch 186/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.8750\n",
            "Epoch 187/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3256 - accuracy: 0.9375\n",
            "Epoch 188/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3616 - accuracy: 0.9286\n",
            "Epoch 189/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.9107\n",
            "Epoch 190/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.9018\n",
            "Epoch 191/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.9286\n",
            "Epoch 192/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.8482\n",
            "Epoch 193/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.9018\n",
            "Epoch 194/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.9196\n",
            "Epoch 195/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.8661\n",
            "Epoch 196/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5257 - accuracy: 0.8482\n",
            "Epoch 197/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8839\n",
            "Epoch 198/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3615 - accuracy: 0.9196\n",
            "Epoch 199/700\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4497 - accuracy: 0.8571\n",
            "Epoch 200/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3757 - accuracy: 0.8839\n",
            "Epoch 201/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3747 - accuracy: 0.9196\n",
            "Epoch 202/700\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3106 - accuracy: 0.9286\n",
            "Epoch 203/700\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3096 - accuracy: 0.9375\n",
            "Epoch 204/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8661\n",
            "Epoch 205/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.9018\n",
            "Epoch 206/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.8393\n",
            "Epoch 207/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.9018\n",
            "Epoch 208/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.8750\n",
            "Epoch 209/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8571\n",
            "Epoch 210/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.9375\n",
            "Epoch 211/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8929\n",
            "Epoch 212/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.9196\n",
            "Epoch 213/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8839\n",
            "Epoch 214/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 0.9554\n",
            "Epoch 215/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.9196\n",
            "Epoch 216/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.8571\n",
            "Epoch 217/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8750\n",
            "Epoch 218/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.9107\n",
            "Epoch 219/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.9018\n",
            "Epoch 220/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8750\n",
            "Epoch 221/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8304\n",
            "Epoch 222/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.9286\n",
            "Epoch 223/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8839\n",
            "Epoch 224/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8661\n",
            "Epoch 225/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.9018\n",
            "Epoch 226/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.9018\n",
            "Epoch 227/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.9107\n",
            "Epoch 228/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.9196\n",
            "Epoch 229/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.9018\n",
            "Epoch 230/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.9107\n",
            "Epoch 231/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.9107\n",
            "Epoch 232/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.9196\n",
            "Epoch 233/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.8571\n",
            "Epoch 234/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8661\n",
            "Epoch 235/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.9196\n",
            "Epoch 236/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.9196\n",
            "Epoch 237/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.9196\n",
            "Epoch 238/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.8482\n",
            "Epoch 239/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.9107\n",
            "Epoch 240/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.9018\n",
            "Epoch 241/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2518 - accuracy: 0.9464\n",
            "Epoch 242/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8929\n",
            "Epoch 243/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.9375\n",
            "Epoch 244/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.9286\n",
            "Epoch 245/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9375\n",
            "Epoch 246/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.9018\n",
            "Epoch 247/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.9196\n",
            "Epoch 248/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.9196\n",
            "Epoch 249/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8661\n",
            "Epoch 250/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8839\n",
            "Epoch 251/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.9196\n",
            "Epoch 252/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.9286\n",
            "Epoch 253/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.9107\n",
            "Epoch 254/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.9554\n",
            "Epoch 255/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8750\n",
            "Epoch 256/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8661\n",
            "Epoch 257/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8571\n",
            "Epoch 258/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8929\n",
            "Epoch 259/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.9018\n",
            "Epoch 260/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.9286\n",
            "Epoch 261/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.9196\n",
            "Epoch 262/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.9018\n",
            "Epoch 263/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8750\n",
            "Epoch 264/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8839\n",
            "Epoch 265/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8839\n",
            "Epoch 266/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9464\n",
            "Epoch 267/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.9286\n",
            "Epoch 268/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.9107\n",
            "Epoch 269/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.9286\n",
            "Epoch 270/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.9554\n",
            "Epoch 271/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.9375\n",
            "Epoch 272/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.9196\n",
            "Epoch 273/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.9107\n",
            "Epoch 274/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.9196\n",
            "Epoch 275/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.9375\n",
            "Epoch 276/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.9196\n",
            "Epoch 277/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8929\n",
            "Epoch 278/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.9196\n",
            "Epoch 279/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.8393\n",
            "Epoch 280/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.8482\n",
            "Epoch 281/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.9018\n",
            "Epoch 282/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2577 - accuracy: 0.9464\n",
            "Epoch 283/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.9375\n",
            "Epoch 284/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8929\n",
            "Epoch 285/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.9107\n",
            "Epoch 286/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2903 - accuracy: 0.9196\n",
            "Epoch 287/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8929\n",
            "Epoch 288/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.9196\n",
            "Epoch 289/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.9286\n",
            "Epoch 290/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8750\n",
            "Epoch 291/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.9375\n",
            "Epoch 292/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.9107\n",
            "Epoch 293/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.9196\n",
            "Epoch 294/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.9107\n",
            "Epoch 295/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.9018\n",
            "Epoch 296/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.9107\n",
            "Epoch 297/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8929\n",
            "Epoch 298/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.8661\n",
            "Epoch 299/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8839\n",
            "Epoch 300/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.8661\n",
            "Epoch 301/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7946\n",
            "Epoch 302/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8839\n",
            "Epoch 303/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.9196\n",
            "Epoch 304/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.9107\n",
            "Epoch 305/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.9375\n",
            "Epoch 306/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.9107\n",
            "Epoch 307/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.9286\n",
            "Epoch 308/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.9196\n",
            "Epoch 309/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.8571\n",
            "Epoch 310/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.8661\n",
            "Epoch 311/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.9196\n",
            "Epoch 312/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3010 - accuracy: 0.9286\n",
            "Epoch 313/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8839\n",
            "Epoch 314/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2962 - accuracy: 0.9375\n",
            "Epoch 315/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8571\n",
            "Epoch 316/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8750\n",
            "Epoch 317/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8839\n",
            "Epoch 318/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8482\n",
            "Epoch 319/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8839\n",
            "Epoch 320/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9375\n",
            "Epoch 321/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.9643\n",
            "Epoch 322/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.9375\n",
            "Epoch 323/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8839\n",
            "Epoch 324/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2820 - accuracy: 0.9554\n",
            "Epoch 325/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.9286\n",
            "Epoch 326/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8929\n",
            "Epoch 327/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.9375\n",
            "Epoch 328/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.9464\n",
            "Epoch 329/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8571\n",
            "Epoch 330/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.9286\n",
            "Epoch 331/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.9286\n",
            "Epoch 332/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8929\n",
            "Epoch 333/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.9018\n",
            "Epoch 334/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2876 - accuracy: 0.9286\n",
            "Epoch 335/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2415 - accuracy: 0.9464\n",
            "Epoch 336/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.9196\n",
            "Epoch 337/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2603 - accuracy: 0.9375\n",
            "Epoch 338/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3125 - accuracy: 0.8929\n",
            "Epoch 339/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.9196\n",
            "Epoch 340/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.9107\n",
            "Epoch 341/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8750\n",
            "Epoch 342/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.8661\n",
            "Epoch 343/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2848 - accuracy: 0.9107\n",
            "Epoch 344/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.9554\n",
            "Epoch 345/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9554\n",
            "Epoch 346/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.9286\n",
            "Epoch 347/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8839\n",
            "Epoch 348/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.9464\n",
            "Epoch 349/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8929\n",
            "Epoch 350/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8929\n",
            "Epoch 351/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9643\n",
            "Epoch 352/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.8393\n",
            "Epoch 353/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9196\n",
            "Epoch 354/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.9196\n",
            "Epoch 355/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8839\n",
            "Epoch 356/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8482\n",
            "Epoch 357/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8750\n",
            "Epoch 358/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8929\n",
            "Epoch 359/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.9196\n",
            "Epoch 360/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8839\n",
            "Epoch 361/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9643\n",
            "Epoch 362/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2831 - accuracy: 0.9107\n",
            "Epoch 363/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.9286\n",
            "Epoch 364/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.9107\n",
            "Epoch 365/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8839\n",
            "Epoch 366/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.9464\n",
            "Epoch 367/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8929\n",
            "Epoch 368/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8929\n",
            "Epoch 369/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9554\n",
            "Epoch 370/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9196\n",
            "Epoch 371/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.9196\n",
            "Epoch 372/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2533 - accuracy: 0.9107\n",
            "Epoch 373/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.9196\n",
            "Epoch 374/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.9464\n",
            "Epoch 375/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8929\n",
            "Epoch 376/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.9375\n",
            "Epoch 377/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.9107\n",
            "Epoch 378/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2573 - accuracy: 0.9196\n",
            "Epoch 379/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9554\n",
            "Epoch 380/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8393\n",
            "Epoch 381/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8929\n",
            "Epoch 382/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.9286\n",
            "Epoch 383/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.9018\n",
            "Epoch 384/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8929\n",
            "Epoch 385/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9554\n",
            "Epoch 386/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.9107\n",
            "Epoch 387/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.9107\n",
            "Epoch 388/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9643\n",
            "Epoch 389/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.9286\n",
            "Epoch 390/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8839\n",
            "Epoch 391/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.9196\n",
            "Epoch 392/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8929\n",
            "Epoch 393/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8750\n",
            "Epoch 394/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.9196\n",
            "Epoch 395/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.9821\n",
            "Epoch 396/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8839\n",
            "Epoch 397/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9464\n",
            "Epoch 398/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.9196\n",
            "Epoch 399/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8929\n",
            "Epoch 400/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.9375\n",
            "Epoch 401/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2957 - accuracy: 0.9196\n",
            "Epoch 402/700\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9643\n",
            "Epoch 403/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.9107\n",
            "Epoch 404/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.9554\n",
            "Epoch 405/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.9107\n",
            "Epoch 406/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2856 - accuracy: 0.9107\n",
            "Epoch 407/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.9196\n",
            "Epoch 408/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.9018\n",
            "Epoch 409/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.9107\n",
            "Epoch 410/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8929\n",
            "Epoch 411/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.9286\n",
            "Epoch 412/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8839\n",
            "Epoch 413/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.9196\n",
            "Epoch 414/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.9018\n",
            "Epoch 415/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.9018\n",
            "Epoch 416/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.9464\n",
            "Epoch 417/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9107\n",
            "Epoch 418/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9732\n",
            "Epoch 419/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.9107\n",
            "Epoch 420/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.9375\n",
            "Epoch 421/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9554\n",
            "Epoch 422/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9464\n",
            "Epoch 423/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8929\n",
            "Epoch 424/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.9196\n",
            "Epoch 425/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.9464\n",
            "Epoch 426/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9554\n",
            "Epoch 427/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8661\n",
            "Epoch 428/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.9196\n",
            "Epoch 429/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.8929\n",
            "Epoch 430/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8661\n",
            "Epoch 431/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9375\n",
            "Epoch 432/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8929\n",
            "Epoch 433/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.9107\n",
            "Epoch 434/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.9018\n",
            "Epoch 435/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.9196\n",
            "Epoch 436/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.9107\n",
            "Epoch 437/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9286\n",
            "Epoch 438/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9375\n",
            "Epoch 439/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.9196\n",
            "Epoch 440/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8929\n",
            "Epoch 441/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2168 - accuracy: 0.9375\n",
            "Epoch 442/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8750\n",
            "Epoch 443/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9375\n",
            "Epoch 444/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9554\n",
            "Epoch 445/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9821\n",
            "Epoch 446/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9464\n",
            "Epoch 447/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.9375\n",
            "Epoch 448/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.9286\n",
            "Epoch 449/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8571\n",
            "Epoch 450/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9196\n",
            "Epoch 451/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8839\n",
            "Epoch 452/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.9286\n",
            "Epoch 453/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9196\n",
            "Epoch 454/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9732\n",
            "Epoch 455/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9554\n",
            "Epoch 456/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.9196\n",
            "Epoch 457/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.9196\n",
            "Epoch 458/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8839\n",
            "Epoch 459/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9196\n",
            "Epoch 460/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.9196\n",
            "Epoch 461/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.9286\n",
            "Epoch 462/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9375\n",
            "Epoch 463/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.9286\n",
            "Epoch 464/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8661\n",
            "Epoch 465/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.9375\n",
            "Epoch 466/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.9286\n",
            "Epoch 467/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.9286\n",
            "Epoch 468/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.9107\n",
            "Epoch 469/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9375\n",
            "Epoch 470/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1996 - accuracy: 0.9464\n",
            "Epoch 471/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.9018\n",
            "Epoch 472/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9464\n",
            "Epoch 473/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.9196\n",
            "Epoch 474/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9464\n",
            "Epoch 475/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2390 - accuracy: 0.9196\n",
            "Epoch 476/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2263 - accuracy: 0.9464\n",
            "Epoch 477/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.9375\n",
            "Epoch 478/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9554\n",
            "Epoch 479/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.9286\n",
            "Epoch 480/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2787 - accuracy: 0.8929\n",
            "Epoch 481/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9464\n",
            "Epoch 482/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9375\n",
            "Epoch 483/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9464\n",
            "Epoch 484/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.9286\n",
            "Epoch 485/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.9375\n",
            "Epoch 486/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.9107\n",
            "Epoch 487/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.9018\n",
            "Epoch 488/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.9464\n",
            "Epoch 489/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9375\n",
            "Epoch 490/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.9286\n",
            "Epoch 491/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9554\n",
            "Epoch 492/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.9018\n",
            "Epoch 493/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3130 - accuracy: 0.9018\n",
            "Epoch 494/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.9286\n",
            "Epoch 495/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2381 - accuracy: 0.9286\n",
            "Epoch 496/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.9286\n",
            "Epoch 497/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9375\n",
            "Epoch 498/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.9107\n",
            "Epoch 499/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9464\n",
            "Epoch 500/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.9196\n",
            "Epoch 501/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3420 - accuracy: 0.9107\n",
            "Epoch 502/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2285 - accuracy: 0.9286\n",
            "Epoch 503/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.9375\n",
            "Epoch 504/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2755 - accuracy: 0.9286\n",
            "Epoch 505/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.9286\n",
            "Epoch 506/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2789 - accuracy: 0.8929\n",
            "Epoch 507/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3165 - accuracy: 0.9018\n",
            "Epoch 508/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.9107\n",
            "Epoch 509/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2147 - accuracy: 0.9286\n",
            "Epoch 510/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1948 - accuracy: 0.9375\n",
            "Epoch 511/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8661\n",
            "Epoch 512/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.9375\n",
            "Epoch 513/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9464\n",
            "Epoch 514/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1985 - accuracy: 0.9464\n",
            "Epoch 515/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.9018\n",
            "Epoch 516/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.9375\n",
            "Epoch 517/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9286\n",
            "Epoch 518/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.9196\n",
            "Epoch 519/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2234 - accuracy: 0.9554\n",
            "Epoch 520/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8839\n",
            "Epoch 521/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.9018\n",
            "Epoch 522/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.9286\n",
            "Epoch 523/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.9554\n",
            "Epoch 524/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.9643\n",
            "Epoch 525/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.9018\n",
            "Epoch 526/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2092 - accuracy: 0.9554\n",
            "Epoch 527/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2092 - accuracy: 0.9643\n",
            "Epoch 528/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2839 - accuracy: 0.9018\n",
            "Epoch 529/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.9018\n",
            "Epoch 530/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.9196\n",
            "Epoch 531/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2324 - accuracy: 0.9286\n",
            "Epoch 532/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9464\n",
            "Epoch 533/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1968 - accuracy: 0.9554\n",
            "Epoch 534/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2576 - accuracy: 0.9286\n",
            "Epoch 535/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1461 - accuracy: 0.9821\n",
            "Epoch 536/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2651 - accuracy: 0.9018\n",
            "Epoch 537/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1815 - accuracy: 0.9643\n",
            "Epoch 538/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.9286\n",
            "Epoch 539/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9554\n",
            "Epoch 540/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2466 - accuracy: 0.9554\n",
            "Epoch 541/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.9107\n",
            "Epoch 542/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9464\n",
            "Epoch 543/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.9286\n",
            "Epoch 544/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8929\n",
            "Epoch 545/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.9196\n",
            "Epoch 546/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2274 - accuracy: 0.9732\n",
            "Epoch 547/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2526 - accuracy: 0.9375\n",
            "Epoch 548/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.8750\n",
            "Epoch 549/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9107\n",
            "Epoch 550/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1971 - accuracy: 0.9286\n",
            "Epoch 551/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1800 - accuracy: 0.9732\n",
            "Epoch 552/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9375\n",
            "Epoch 553/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.9107\n",
            "Epoch 554/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.9554\n",
            "Epoch 555/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9554\n",
            "Epoch 556/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.9196\n",
            "Epoch 557/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2913 - accuracy: 0.9286\n",
            "Epoch 558/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.9375\n",
            "Epoch 559/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.9375\n",
            "Epoch 560/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.9554\n",
            "Epoch 561/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.9196\n",
            "Epoch 562/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.9107\n",
            "Epoch 563/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1933 - accuracy: 0.9464\n",
            "Epoch 564/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2002 - accuracy: 0.9554\n",
            "Epoch 565/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9286\n",
            "Epoch 566/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2285 - accuracy: 0.9554\n",
            "Epoch 567/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.9196\n",
            "Epoch 568/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9464\n",
            "Epoch 569/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.9196\n",
            "Epoch 570/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.9107\n",
            "Epoch 571/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2078 - accuracy: 0.9554\n",
            "Epoch 572/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2550 - accuracy: 0.9375\n",
            "Epoch 573/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2738 - accuracy: 0.9375\n",
            "Epoch 574/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9464\n",
            "Epoch 575/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8482\n",
            "Epoch 576/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8839\n",
            "Epoch 577/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3113 - accuracy: 0.9018\n",
            "Epoch 578/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9464\n",
            "Epoch 579/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8929\n",
            "Epoch 580/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2084 - accuracy: 0.9375\n",
            "Epoch 581/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.8929\n",
            "Epoch 582/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8929\n",
            "Epoch 583/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2285 - accuracy: 0.9286\n",
            "Epoch 584/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.9375\n",
            "Epoch 585/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2084 - accuracy: 0.9286\n",
            "Epoch 586/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2122 - accuracy: 0.9554\n",
            "Epoch 587/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.9375\n",
            "Epoch 588/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.9375\n",
            "Epoch 589/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9643\n",
            "Epoch 590/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.9107\n",
            "Epoch 591/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9464\n",
            "Epoch 592/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2342 - accuracy: 0.9286\n",
            "Epoch 593/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.9018\n",
            "Epoch 594/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8839\n",
            "Epoch 595/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9643\n",
            "Epoch 596/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.9464\n",
            "Epoch 597/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9464\n",
            "Epoch 598/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8929\n",
            "Epoch 599/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9732\n",
            "Epoch 600/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9554\n",
            "Epoch 601/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2153 - accuracy: 0.9286\n",
            "Epoch 602/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2207 - accuracy: 0.9464\n",
            "Epoch 603/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.9286\n",
            "Epoch 604/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.9286\n",
            "Epoch 605/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.9196\n",
            "Epoch 606/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2188 - accuracy: 0.9286\n",
            "Epoch 607/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.9018\n",
            "Epoch 608/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9375\n",
            "Epoch 609/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1990 - accuracy: 0.9643\n",
            "Epoch 610/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1776 - accuracy: 0.9732\n",
            "Epoch 611/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2206 - accuracy: 0.9286\n",
            "Epoch 612/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2248 - accuracy: 0.9643\n",
            "Epoch 613/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.9375\n",
            "Epoch 614/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.9375\n",
            "Epoch 615/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2064 - accuracy: 0.9643\n",
            "Epoch 616/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1471 - accuracy: 0.9643\n",
            "Epoch 617/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9464\n",
            "Epoch 618/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9554\n",
            "Epoch 619/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.9286\n",
            "Epoch 620/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9375\n",
            "Epoch 621/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.9286\n",
            "Epoch 622/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2483 - accuracy: 0.9286\n",
            "Epoch 623/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2100 - accuracy: 0.9554\n",
            "Epoch 624/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9286\n",
            "Epoch 625/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9554\n",
            "Epoch 626/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2637 - accuracy: 0.9018\n",
            "Epoch 627/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.9018\n",
            "Epoch 628/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9464\n",
            "Epoch 629/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.9375\n",
            "Epoch 630/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.9286\n",
            "Epoch 631/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.9196\n",
            "Epoch 632/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.9464\n",
            "Epoch 633/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.9286\n",
            "Epoch 634/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.9018\n",
            "Epoch 635/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8929\n",
            "Epoch 636/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9464\n",
            "Epoch 637/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9375\n",
            "Epoch 638/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.9464\n",
            "Epoch 639/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8661\n",
            "Epoch 640/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2199 - accuracy: 0.9554\n",
            "Epoch 641/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9286\n",
            "Epoch 642/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.9286\n",
            "Epoch 643/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9554\n",
            "Epoch 644/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.9107\n",
            "Epoch 645/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2372 - accuracy: 0.9196\n",
            "Epoch 646/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.9196\n",
            "Epoch 647/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.9464\n",
            "Epoch 648/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9464\n",
            "Epoch 649/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.9286\n",
            "Epoch 650/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9286\n",
            "Epoch 651/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9375\n",
            "Epoch 652/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1828 - accuracy: 0.9643\n",
            "Epoch 653/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3188 - accuracy: 0.9196\n",
            "Epoch 654/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.9196\n",
            "Epoch 655/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.9018\n",
            "Epoch 656/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2031 - accuracy: 0.9464\n",
            "Epoch 657/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.9107\n",
            "Epoch 658/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.9286\n",
            "Epoch 659/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.9464\n",
            "Epoch 660/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9732\n",
            "Epoch 661/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9018\n",
            "Epoch 662/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.9107\n",
            "Epoch 663/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.8929\n",
            "Epoch 664/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2088 - accuracy: 0.9286\n",
            "Epoch 665/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.9196\n",
            "Epoch 666/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2095 - accuracy: 0.9375\n",
            "Epoch 667/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.9286\n",
            "Epoch 668/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.9018\n",
            "Epoch 669/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9464\n",
            "Epoch 670/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2612 - accuracy: 0.9464\n",
            "Epoch 671/700\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2917 - accuracy: 0.8929\n",
            "Epoch 672/700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1820 - accuracy: 0.9464\n",
            "Epoch 673/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2113 - accuracy: 0.9643\n",
            "Epoch 674/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1991 - accuracy: 0.9375\n",
            "Epoch 675/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.9554\n",
            "Epoch 676/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9643\n",
            "Epoch 677/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.9286\n",
            "Epoch 678/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1806 - accuracy: 0.9643\n",
            "Epoch 679/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.9107\n",
            "Epoch 680/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.9286\n",
            "Epoch 681/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.9196\n",
            "Epoch 682/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9286\n",
            "Epoch 683/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.9018\n",
            "Epoch 684/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9643\n",
            "Epoch 685/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.9286\n",
            "Epoch 686/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9107\n",
            "Epoch 687/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9286\n",
            "Epoch 688/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.9018\n",
            "Epoch 689/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.9286\n",
            "Epoch 690/700\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9732\n",
            "Epoch 691/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9464\n",
            "Epoch 692/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.9018\n",
            "Epoch 693/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.9286\n",
            "Epoch 694/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9464\n",
            "Epoch 695/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9554\n",
            "Epoch 696/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2407 - accuracy: 0.9196\n",
            "Epoch 697/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8839\n",
            "Epoch 698/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.9018\n",
            "Epoch 699/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.9107\n",
            "Epoch 700/700\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_new, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G93cNuxiz18",
        "outputId": "f9e5e8e5-b977-4525-ac1b-5c48ebceda64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1187 - accuracy: 0.9474\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11871310323476791, 0.9473684430122375]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA6AGyer2m5L"
      },
      "source": [
        "## Загрузка изображений в TensorFlow/Keras\n",
        "Первоначально загрузим библиотеки для создания сверточной нейронной сети CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LNokdGtJZqGm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для примера загрузим набор изображений cifar10 из библиотеки keras."
      ],
      "metadata": {
        "id": "PE6eW1nzRVKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
        "assert train_images.shape == (50000, 32, 32, 3)\n",
        "assert test_images.shape == (10000, 32, 32, 3)\n",
        "assert train_labels.shape == (50000, 1)\n",
        "assert test_labels.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "SM0eIIidmTxP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvsVQy0s32Gy"
      },
      "source": [
        "Отобразим на экране некоторые изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9bcin9q4aBs"
      },
      "source": [
        "Создадим сверточную нейронную сеть с 3 сверточными слоями. Последний слой будет состоять из 10 выходов соответствующих классам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2otUHVPmZqQ5"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32,\n",
        "32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLk1NgcW4hDU"
      },
      "source": [
        "Скомпилируем сверточную нейронную сеть и определим весовые коэффициенты по данным обучающей группы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otY-SQsyZqTZ",
        "outputId": "4cd79b6d-d56f-456c-9b16-ecb9a20ead6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 88s 56ms/step - loss: 1.7439 - accuracy: 0.3907 - val_loss: 1.3959 - val_accuracy: 0.4927\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 81s 52ms/step - loss: 1.3375 - accuracy: 0.5242 - val_loss: 1.2546 - val_accuracy: 0.5574\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 107s 69ms/step - loss: 1.1737 - accuracy: 0.5880 - val_loss: 1.2058 - val_accuracy: 0.5773\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 98s 63ms/step - loss: 1.0731 - accuracy: 0.6267 - val_loss: 1.1092 - val_accuracy: 0.6165\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 87s 56ms/step - loss: 0.9788 - accuracy: 0.6582 - val_loss: 1.0553 - val_accuracy: 0.6399\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.9093 - accuracy: 0.6833 - val_loss: 1.0728 - val_accuracy: 0.6455\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.8503 - accuracy: 0.7063 - val_loss: 1.1185 - val_accuracy: 0.6321\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 98s 63ms/step - loss: 0.8039 - accuracy: 0.7224 - val_loss: 1.0765 - val_accuracy: 0.6542\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 86s 55ms/step - loss: 0.7521 - accuracy: 0.7371 - val_loss: 1.0752 - val_accuracy: 0.6585\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 84s 53ms/step - loss: 0.7179 - accuracy: 0.7506 - val_loss: 1.0542 - val_accuracy: 0.6583\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 81s 52ms/step - loss: 0.6720 - accuracy: 0.7667 - val_loss: 1.0606 - val_accuracy: 0.6668\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 85s 55ms/step - loss: 0.6424 - accuracy: 0.7760 - val_loss: 1.1284 - val_accuracy: 0.6579\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 81s 52ms/step - loss: 0.6151 - accuracy: 0.7868 - val_loss: 1.0985 - val_accuracy: 0.6684\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 82s 52ms/step - loss: 0.5916 - accuracy: 0.7927 - val_loss: 1.1660 - val_accuracy: 0.6581\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 84s 54ms/step - loss: 0.5610 - accuracy: 0.8056 - val_loss: 1.1343 - val_accuracy: 0.6712\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        " loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        " metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, epochs=15,\n",
        " validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaRNXfK04nnb"
      },
      "source": [
        "По окончании обучения нейронной сети выведем результаты оценки точности модели на тестововм наборе данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "sn2zZzjpZqVr",
        "outputId": "15f79c10-6985-44f8-89b9-e23e4ae1e106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 5s - loss: 1.1343 - accuracy: 0.6712 - 5s/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx10lEQVR4nO3dd3yUZbbA8d9JgRQICYQASei9hBoBwUWkKLoqrkpx1V2xd8S96yq7q656Xe/uupa9WNDFshZUbOhVFAEFBJEqJfQiCZBKCiE9OfePdxJCTMKATGbCnO/nk8/MW+dkIM953+d9iqgqxhhj/FeAtwMwxhjjXZYIjDHGz1kiMMYYP2eJwBhj/JwlAmOM8XOWCIwxxs95LBGIyBwRSReRzXVsFxF5VkR2ichGERnsqViMMcbUzZN3BK8CE+rZfiHQ3fVzM/C8B2MxxhhTB48lAlVdChyuZ5eJwOvq+A6IFJF2norHGGNM7YK8+NlxQHK15RTXukM1dxSRm3HuGggPDx/Sq1evBgnQGGPOFGvXrs1U1da1bfNmInCbqs4GZgMkJibqmjVrvByRMcY0LiLyY13bvNlq6ADQvtpyvGudMcaYBuTNRDAf+I2r9dBwIFdVf1ItZIwxxrM8VjUkIm8Do4FoEUkBHgKCAVT1BeAz4CJgF1AATPNULMYYY+rmsUSgqledYLsCd3jq840xxrjHehYbY4yfs0RgjDF+zhKBMcb4OUsExhjj5ywRGGOMn7NEYIwxfs4SgTHG+DlLBMYY4+csERhjjJ+zRGCMMX7OEoExxvg5SwTGGOPnLBEYY4yfs0RgjDF+zhKBMcb4OUsExhjj5ywRGGOMn7NEYIwxfs4SgTHG+DlLBMYY4+csERhjjJ+zRGCMMX7OEoExxvg5SwTGGOPnLBEYY4yfs0RgjDF+zhKBMcb4OUsExhjj5ywRGGOMn7NEYIwxfs4SgTHG+DlLBMYY4+csERhjjJ+zRGCMMX7OEoExxvg5jyYCEZkgIttFZJeI3F/L9o4iskhENorI1yIS78l4jDHG/JTHEoGIBAKzgAuBPsBVItKnxm7/AF5X1f7AI8BfPRWPMcaY2nnyjmAosEtV96hqCTAXmFhjnz7AYtf7JbVsN8YY42GeTARxQHK15RTXuup+AC53vf8V0FxEWtU8kYjcLCJrRGRNRkaGR4I1xhh/5e2Hxf8FnCsi64FzgQNAec2dVHW2qiaqamLr1q0bOkZjjDmjBXnw3AeA9tWW413rqqjqQVx3BCLSDLhCVXM8GJMxxpgaPHlHsBroLiKdRaQJMBWYX30HEYkWkcoYHgDmeDAeY4wxtfBYIlDVMuBO4AtgK/Cuqm4RkUdE5FLXbqOB7SKyA2gD/Len4jHGGFM7UVVvx3BSEhMTdc2aNd4OwxhjGhURWauqibVt8/bDYmOMMV5micAYY/ycJQJjjPFzlgiMMcbPWSIwxhg/Z4nAGGP8nCUCY4zxc5YIjDHGz1kiMMYYP2eJwBhj/JwlAmOM8XOWCIwxxs9ZIjDGGD9nicAYY/ycJQJjjPFzlgiMMcbPWSIwxhg/Z4nAGGP8nCUCY4zxc5YIjDHGz1kiMMYYP2eJwBhj/JwlAmOM8XOWCIwxxs9ZIjDGGD9nicAYY/ycJQJjjPFzlgiMMcbPWSIwxhg/Z4nAGGP8nCUCY4zxc5YIjDHGz1kiMMYYP2eJwBhjGglV9ch5PZoIRGSCiGwXkV0icn8t2zuIyBIRWS8iG0XkIk/GY4wxjUn20RIWbD7Egx9vZtw/v2HB5lSPfE6QR84KiEggMAsYD6QAq0VkvqomVdvtT8C7qvq8iPQBPgM6eSomY4zxZUeKSlm97zArdmWxYncWW1PzUIWwJoGc1aklzUI8U2R7LBEAQ4FdqroHQETmAhOB6olAgQjX+xbAQQ/GY4wxPqWotJy1P2azYncmK3ZnsTEll/IKpUlQAEM6RHHvuB6M6NaK/vGRBAd6rgLHk4kgDkiutpwCDKuxz8PAlyJyFxAOjKvtRCJyM3AzQIcOHU57oMYY0xBKyir4ISXHdcWfyfr9OZSUVxAYIAyIb8Ft53ZlRNdWDO4YRUhwYIPF5clE4I6rgFdV9UkRORv4j4j0U9WK6jup6mxgNkBiYqJnnpYYY8xpVl6hbD6Qy4rdTsG/Zl82haXliEDf2AiuG9mJs7u2cqp9mnqvOD7hJ4vIJcD/1Syc3XAAaF9tOd61rrobgAkAqrpSREKAaCD9JD/LGGO8qqJCycwvJiWnkA37c1ixO4tVe7M4UlQGQI82zZhyVnuGd2nF8C4tiQxr4uWIj3EnBU0BnhaR94E5qrrNzXOvBrqLSGecBDAV+HWNffYDY4FXRaQ3EAJkuHl+Y4xpMEWl5RzKLeJAdiEHcwpJyXFeD2QXcjC3kEM5RZSUH7te7tQqjIv7t+PsrtEM79KSmOYhXoy+fidMBKp6jYhE4KrGEREFXgHeVtUj9RxXJiJ3Al8AgThJZIuIPAKsUdX5wO+Al0RkBs6D4+vUUw1ljTGmDqpKdkGpU7BXFu6u95Wvmfklxx0jAm2ahxAbGUL/+Egm9AshPjKU2MhQerWLIC4y1Eu/zckTd8tdEWkFXAvcA2wFugHPquq/PBZdLRITE3XNmjUN+ZHGmDOEqnIwt4gN+3PYkJzN9rR8DmQXcDCniMLS8uP2DQkOIM5VsMdHhRLbwnkfFxVKXGQobSJCaBLUePrkishaVU2sbZs7zwguBabhFPyvA0NVNV1EwnCagjZoIjDGGHflF5exMSWH9ftz2JDs/GQcKQagSVAAPds0p0eb5ozuGVNV6Me5CvuosGBExMu/QcNw5xnBFcBTqrq0+kpVLRCRGzwTljHGnJzyCmVn+hGn0HcV/DvSj1BZ6dE5OpxzukUzqEMkA9tH0qttRKO6ovckdxLBw8ChygURCQXaqOo+VV3kqcCMMaY+aXlF1a70s9mUksvREqd6JzIsmAHxkVyY0JaB7Z2C35da6fgadxLBe8CIasvlrnVneSQiY4ypobCknE0HctmQnO0U/PtzOJhbBEBwoNC7XQRXDolnYIdIBraPolOrML+p1jkd3EkEQapa9bhcVUtExFKrMcYjMvOL2Xooj6SDeSQdymProTx2ZxylvMKp44mPCmVIp5bc4LrS7xsb0aC9cM9E7iSCDBG51NXcExGZCGR6NixjzJmuvELZm3nUKfRdBX7SwTzSXQ9zAdq1CKFPuwgu6NuWAfGRDGgfSevmTb0Y9ZnJnURwK/CmiPwvIDjjB/3Go1EZY84oR4vL2JZ6hCRXYb/1UB7bUvMoKnU6YAUFCN1imnFO92j6tIugT7sIereLICrcKh8agjsdynYDw0WkmWs53+NRGWMaJVUlNa+oRtXOEfZlHa1qvRMREkSf2AiuGtrBKfRjI+gW04ymQVa94y1ujXIkIr8E+gIhlQ9gVPURD8ZljGkkSsoqWLkniwWbU/lqa1pVO32ADi3D6NMugssGxtEnNoLe7ZoTFxlqD3J9jDsdyl4AwoDzgJeBK4HvPRyXMcaHFZWW882ODL5wFf55RWWENQnkvJ4xDO3ckj6xEfRq25zmIcHeDtW4wZ07ghGq2l9ENqrqX0TkSeBzTwdmjPEtR4pKWbwtnS+2pLJkWwaFpeW0CA1mfJ+2XNivLed0j7bWO42UO4mgyPVaICKxQBbQznMhGWN8xeGjJXyVlMaCLaks35lJSXkF0c2acvngOC7s145hXVp6dOYs0zDcSQSfiEgk8HdgHc4ooS95MihjjPek5RXxxZZUFmxOZdXew5RXKHGRofzm7I5M6NeWQR2iCAywOv4zSb2JQEQCgEWqmgO8LyKfAiGqmtsQwRljGsb+rAIWbDnEgs2prNufA0DX1uHcdm5XJvRrS9/YCHvAewarNxGoaoWIzAIGuZaLgeL6jjHG+D5VZVd6Pgs2p/L55lSSDuUBzvSJ/3V+Dyb0a0u3mOZejtI0FHeqhhaJyBXABzZpjDGNV25hKSt3Z7F8VwbLd2ayL6sAERjSIYo//bI3F/RtS/uWYd4O03iBO4ngFuBeoExEinB6F6uqRng0MmPMz1JaXsGG5ByW7cxk+c4MfkjJpbxCCW8SyPAurbjhnM5c0LctMRG+O4WiaRju9Cy2+0NjGgFVZU/mUZbvzGTZzky+25NFfnEZAQL94yO5fXRX13j8UTYOvzmOOx3KRtW2vuZENcaYhnf4aAnf7spk+c5Mlu/K5EBOIeD06L10YCyjukdzdpdoWoRZxy5TN3eqhn5f7X0IMBRYC4zxSETGmDoVl5Wzdl82y1yF/+aDuag64/eM6BrN7ed15RfdWtOhldX1G/e5UzV0SfVlEWkPPO2pgIwxx6gq29OOVFX3rNqbRVFpBUEBwuAOUdw7rgfndI+mf3ykte03p8ytQedqSAF6n+5AjDGOgpIyvt2VxeJt6Xy9PZ1Drpm4urYOZ+pZHfhF92iGdWlFs6an8udrzE+584zgXzi9iQECgIE4PYyNMadJ8uEClmxPZ9HWdFbuyaKkrIJmTYP4RfdoZoyL4Rc9omnXItTbYZozlDuXFGuqvS8D3lbVbz0UjzF+oay8grU/ZrN4ezqLt6azM92Z5qNLdDjXDu/ImF4xnNWppbXuMQ3CnUQwDyhS1XIAEQkUkTBVLfBsaMacWQ4fLeGbHeks3pbBN9vTySsqIzhQGNq5JVOHdmBMrxg6R4d7O0zjh9zqWQyMAypnJgsFvgRGeCooY84Eqsq21CMs3pbO4m3prN+fTYVCdLOmXNC3LWN6xXBO92gbs994nTuJIKT69JSqmi8i1jbNmFoUlpSzYncmi7als2TbsQe9CXEtuGtMd8b0iiEhrgUB1sLH+BB3EsFRERmsqusARGQIUOjZsIxpPDLzi1mYlMaXW1JZsTuL4rIKwpsEck73aGaM68Honq1tGAfj09xJBPcA74nIQZxxhtoCUzwZlDG+7mBOYdWY/av3HaZCnd68vx7WgbG92nBW5yibjN00Gu50KFstIr2Anq5V21W11LNhGeN79mYeZcHmVBZsPsQPKc6UHD3bNOfOMd2Z0Lctvds1tzH7TaPkTj+CO4A3VXWzazlKRK5S1ec8Hp0xXqSqbD10hAVbUvlicyrb044AMCC+BfdN6MmEvm3p0rqZl6M05udzp2roJlWdVbmgqtkichNgicCccSoqlA0pOXyxOZUFW1L5MauAAIGzOrXkoUv6cH7ftsRFWscuc2ZxJxEEiohUTkojIoFAE8+GZUzDKSuv4Pt9h1mwOZUvtqSSlldMcKAwoms0t57blfF92hDdrKm3wzTGY9xJBAuAd0TkRdfyLcDnngvJGM8rLivn212ZLNicysKkNLILSgkJDuDcHq25sF87zusVQ4tQa99v/IM7ieAPwM3Ara7ljTgth4xpdDYfyGXO8r18mZRGfnEZzZsGMbZ3DBP6tWVUj9aENbGB3Iz/cafVUIWIrAK6ApOBaOB9d04uIhOAZ4BA4GVVfaLG9qeA81yLYUCMqka6Hb0xblBVlu/K5MVv9rB8VybNmwbxy4R2TEhoy4iurayZp/F7dSYCEekBXOX6yQTeAVDV8+o6psbxgcAsYDzO0NWrRWS+qiZV7qOqM6rtfxcw6BR+B2NqVVZewf9tOsSL3+wh6VAeMc2b8sCFvbhqWAcibFgHY6rUd0ewDVgGXKyquwBEZEY9+9c0FNilqntcx84FJgJJdex/FfDQSZzfmFoVlJTx3poUXlq2h5TsQrq2DudvV/Zn4sBYu/o3phb1JYLLganAEhFZAMzF6VnsrjggudpyCjCsth1FpCPQGVhcx/abcZ5T0KFDh5MIwfiTrPxiXlv5I/9ZuY/sglISO0bx8CV9GdMrxsb2MaYedSYCVf0I+EhEwnGu5O8BYkTkeeBDVf3yNMYxFZhXOdR1LbHMBmYDJCYmam37GP+1P6uAl5bt4d01yRSXVTC+TxtuGdWFxE4tvR2aMY2COw+LjwJvAW+JSBQwCacl0YkSwQGgfbXleNe62kwF7jhhtMZUsykllxeX7uazTYcIDBAuHxTPTaO60C3GevsaczJOqq2cqmbjXJnPdmP31UB3EemMkwCmAr+uuZNrHKMoYOXJxGL8k6qybGcmLy7dzbe7smjeNIibRnXh+pGdaWMjfBpzSjzWaFpVy0TkTuALnOajc1R1i4g8AqxR1fmuXacCcyt7LhtTm8oWQC98s4eth/JoE2EtgIw5XaSxlb+JiYm6Zs2aE+9ozggFJWW8szqZl5ft5UBOId1imnHzqC7WAsiYkyQia1U1sbZt1o3S+KTcwlLmLN/Layv3kVNQylmdovjLpdYCyBhPsERgfEplApjz7V6OFJUxrncbbhvdhSEdrQWQMZ5iicD4hNzCUl75di//Xu4kgAv6tuHusd3pG9vC26EZc8azRGC8Kq+olFeW7+Pfy/eQV1TG+X3aMH2cJQBjGpIlAuMVeUWlvPrtPl5ediwB3D22O/3iLAEY09AsEZgGdaSolFeqJYDxfdow3RKAMfXL3gd7voGOIyG622k/vSUC0yCOVN4BLN9LbmEp43q34Z5xlgCMFxVmQ1EeRHYA8bGWaEczYe83sOdrJwHk/OisP/+/IfrO0/5xlgiMRx0pKuW1Fft4admxBDB9bHcS4i0BnDEqKiB3P6Rvg6ydEB4DbfpCdA8I8pFZbUuLIHUTHFh77OfwbmdbaBTEDoLYwc5r3GCIiG3Y+IqPwI8rnEJ/7zeQttlZ37QFdDoHzr4DOp8LrXt65OMtERiPOFJUyusrf+SlZXvIKShlXO8Ypo/tYQmgMVOFvIOQsRXStzoFf3oSZGyH0qM/3T8gyEkGMX2cxFD5ExHn2SvwinInpgNr4eA65zVtC1SUOdubt4O4ITDoagiJhEMb4OB6WP4UVI572aytkxAqE0TcYAg7jU2Yy4ohZfWxgv/AWie+wKbQYTiMfRA6j4Z2AyDQ88W0JQJzWuUXl7nuAJwEMLZXDPeMswTQqKjC0QxXYb/1+IK/OPfYfuExENMbBl/rvLbuDdHdIT/NKXjTtjiJInkVbJ537LiQFhBTmRj6QJt+zvFNm59arLnJ1a701zuFemViahrhFOYj7nYK//qu9ksLXXcN65wEcnA9bP8ccI2+ENnx+OQQO9D9mCsqIHWjq7rnG9i/EkoLQAKOxdflXGg/DIJDT/57+JlsiAlzWtSWAKaP607/+Ehvh2bqU3AYMlxX9unbjhX8BVnH9gmNcq7qW/dyCuzKQj+8lfufU5jjnDtts/NZaVsgLQlKjhzbJ7Lj8XcOMX2hZZfjr4gLDjsFdWXBf3Cdk7QAAptA2wRXge/6adkVAgJO/fspynPuGA64EsPBdZCz37VRnDueyuqk2MHO5weHOAkqazfs/dop+Pctc55JgPM9dj7XKfg7joTQyFOP7yTUN8SEJQLzs5RXKG+u+pGnFu4gu6CUMb1imD62OwPaR3o7NN+mCiVHnULsaKbrNaOW5UwoznMdJK6pocRVtXKCVwmosa7GsUdSIT/1WExNmkNMr2MFfWWh36yNZ6pyVJ1CNW0LpG85lhyydoJWOPsEhTj14hHxTgLJ3nvsu2jd81i1TdwQ586iIZ5JHM10JYX1x+4e8tOcbQFBzndWcBjyXKPut2h/rODvPAqat/V8jLWwRGA8YuuhPB74YBMbknMY2a0Vv7+gFwP9OQGUl/60EK/vfVlh7edpGgHh0RDe2vlpGuHaoE7hedKvVFuuOPY+rJWrsHdd7beI943WM6VFkLn9WPVS2hbITXGSVOWVfruBEBJxwlM1iMpnJ5V3DAc3OFVGXc51EkDLLj7xvdqgc+a0Kiwp55lFO3lp2R4iQ4N5espAJg6MRXzgP7tXpKyF72ZB0sfHHkhWF9jEVai7CvfWPY8v6KtvC4t2qhb8WXCI85C03QBvR+IeEWgR5/z0vtjb0ZwSSwTmpCzdkcEfP9pE8uFCJifGM/Oi3kSG+UgTwYZUXgbbPoXvnnMehjaNgMQbnKvWmgV80wifuCI0pi6WCIxbMvOLefTTJD7ecJAurcOZe/Nwhnc5iYeFZ4qiPFj/H1j1glO/HdkRJjwBg645tVYvxvgASwSmXqrKu2uSefyzbRSWlDN9bHduP6+rZyeFUYWiXOdhW0gLp+7a27L3waoXYd1/nJYuHUbABY9Dz4sgwCbIMY2bJQJTp90Z+cz8YBOr9h5maKeWPH55P7rFnIar3qI8p5DPPQB5Kc6Dtprvq3dQatkVup4HXc5zelk2UHM7VJ1qn5WznGogCYC+v4LhtzstVYw5Q1giMD9RXFbO81/v5rkluwkJDuCJyxOYnNjevZnBio+4CvMUp7D/yfsDx7cdB0CcJnURcU4rlm7jnPcRsU6zvN1LYMPbsPplpzCOGwJdRjuJIf6s099ksLzUefC7cpbTCiQkEkZOh7Nuch4IGnOGseaj5jir9mQx88NN7M44yqUDYvnzxX1o3bxp3QfkZzj15ds/dwr86j1PARBoFuMU7C3iXAV8jffN20LgCSagLytxdcn/GvYscToTaQUEh0OnkU5S6Hqe0wzyVB/MFmbD2lfh+5ecxNWyKwy/DQb+GpqEn9o5jfER1o/AnFBOQQl//Wwb76xJJj4qlMcu68fonjF1H5C9D1b8C9a/4Yyb0mW0M7xAzYK+eTvPdPIpzIF9y52ksOdryNrlrG/W1nW34PqJaHfic2XuglXPw4a3nG7/nUfB8Dug+/k/r1eqMT7E+hGYOqkq8384yKOfJpFdUMoto7owfVx3wprU8V8jdTN8+zRs/sCpphl4lTNOSnT3Bo2b0EinzXZlu+2c/a67ha9h10LYONdZ37rXsbuFjiOOtexRdbr9r3wOdixw7kj6XQln3+4ME2CMH7E7Aj+WfLiAP360maU7MhgQ34LHL0+ofYpIVWeI3OVPOYVsk2aQOM15aNrQw/W6o6IC0jY5SWH3EmeAr7Iip/t//FBoPxR2L3IGGAtr5bT/P+tGaN7G25Eb4zFWNWSOU1pewb+X7+Xpr3YQKMLvL+jJtWd3IrDmw+CKCudqeflTkPK90+t1+K1OoRka5Z3gT0VpESR/5ySFPUvg0Eand+/w26H/ZK+M9mhMQ7OqIVNlQ3IO97+/kW2pRxjfpw1/ubQvsZE1CsLyUtj0Hnz7jDMyZWQHuOgfTqepxlhoBocce2bAX6CkwPk9rLevMYAlAr9RUaHMWrKLp77aQevmTXnhmiFM6FdjFMSSo7DudVjxv06b/pi+cPnLTtv5Bpgco8E0CfN2BMb4lDPor9vUJbeglBnvbmDxtnQuGxjLo5f1o3lIteaaBYfh+9lOM9DCbKfX7MVPQffxdtVsjB+wRHCG23wgl1vfWEtaXhGPTuzLNcM7HhslNCfZ6TS17jWn2WTPi2DkPdBhmFdjNsY0LEsEZ7B3Vu/nzx9voVV4E9695WwGdXA94E3f5tT/b3rXWU6Y5PScjentvWCNMV5jieAMVFRazoMfb+bdNSmc0y2aZ6YOpFWzps7wDp/f54ybExTqtP45+w7nYbAxxm9ZIjjD7M8q4LY317LlYB53jenGPeN6OM1C93wD86532tOf+wcYesvJzTlrjDljWSI4gyzamsaMdzYAMOe6RMb0auN0Bvv2GfjqYWjVDaa8Ca17eDVOY4xvsURwBiivUJ7+agf/WryLvrERPH/1EDq0CnNGAv3odtg6H/pMhImzbPIUY8xPWCJo5LLyi5k+dwPLd2UyOTGeRyb2IyQ4EDJ2wDtXO4OxjX8URtxlTUGNMbXyaCIQkQnAM0Ag8LKqPlHLPpOBhwEFflDVX3sypjPJ+v3Z3P7mOrKOlvA/VyQw5SzXQ9+kj507gaAQ+M3HzmiaxhhTB48lAhEJBGYB44EUYLWIzFfVpGr7dAceAEaqaraI1DPusamkqrzx3Y888mkSbSJC+OC2EfSLa+FMqL7oL7DiWWfylsn/sYlUjDEn5Mk7gqHALlXdAyAic4GJQFK1fW4CZqlqNoCqpnswnjNCQUkZMz/YxEcbDnJez9Y8NWUgkWFNnAli3r8e9i6FxOudCdWD6plQxhhjXDyZCOKA5GrLKUDNLqs9AETkW5zqo4dVdUHNE4nIzcDNAB06+G+b9z0Z+dz6xlp2pufzu/E9uOO8bs70kSlr4d1r4WgmTHwOBl3t7VCNMY2Itx8WBwHdgdFAPLBURBJUNaf6Tqo6G5gNzjDUDRyjT1iw+RD/9d5GggOF16YNZVSP1k7T0DWvOJ3EmreFG76E2IHeDtUY08h4MhEcANpXW453rasuBVilqqXAXhHZgZMYVnswrkalrLyCv32xndlL9zCgfSTPXT2YuMhQKC2E//sv2PAGdB0LV7wMYS29Ha4xphHyZCJYDXQXkc44CWAqULNF0EfAVcArIhKNU1W0x4MxNSrpR4q48631fL/3MNcM78CfL+5D06BAyP7RqQo69AOMug9G3w8Bgd4O1xjTSHksEahqmYjcCXyBU/8/R1W3iMgjwBpVne/adr6IJAHlwO9VNctTMTUm3+89zB1vreNIUSn/nDyAywfHOxt2LYL3b3BmD7tqLvS80LuBGmMaPZuq0gdtSsnlihdWENsihBeuHUKvthFOwb/8SVj8384ooVPegFZdvR2qMZSWlpKSkkJRUZG3QzFASEgI8fHxBAcHH7fepqpsRLKPlnDrG2uJDm/C+7eNcEYNLcqFD2+F7Z9Bvyvh0mehSbi3QzUGgJSUFJo3b06nTp2OzXVhvEJVycrKIiUlhc6dO7t9nCUCH1Jeodw9dz0ZR4p579aznSSQluQMFZGzHyb8Dwy7xYaKMD6lqKjIkoCPEBFatWpFRkbGSR1nicCHPP3VDpbtzOSvlycwoH0kbJoH8+9yBor77afQ8Wxvh2hMrSwJ+I5T+bewROAjFial8a/Fu5icGM/UbuXw6QxYMwfaD4fJrzn9BIwxxgMsEfiAvZlHue+dNdwcvYk/FLyEPPu1U/0z7DY4/1EIDD7hOYwx5lRZIvCywrSdrJrzBAtlIdH5uRAQD6MfgEHX2IBxxviYsrIygoLOvGLzzPuNGoOyEtj+f+jaVwnd8zVXagA57cfAqFug21jrHGYarb98soWkg3mn9Zx9YiN46JK+J9zvsssuIzk5maKiIqZPn87NN9/MggULmDlzJuXl5URHR7No0SLy8/O56667WLNmDSLCQw89xBVXXEGzZs3Iz88HYN68eXz66ae8+uqrXHfddYSEhLB+/XpGjhzJ1KlTmT59OkVFRYSGhvLKK6/Qs2dPysvL+cMf/sCCBQsICAjgpptuom/fvjz77LN89NFHACxcuJDnnnuODz/88LR+Rz+XJYKGlLUb1r0G69+EgkyOhrTjhdJJtDpnGtMuHOnt6Ixp1ObMmUPLli0pLCzkrLPOYuLEidx0000sXbqUzp07c/jwYQAeffRRWrRowaZNmwDIzs4+4blTUlJYsWIFgYGB5OXlsWzZMoKCgvjqq6+YOXMm77//PrNnz2bfvn1s2LCBoKAgDh8+TFRUFLfffjsZGRm0bt2aV155heuvv96j38OpsETgaWXFsPUTWPsq7FsGEgg9L2R7/JVc8lkwo3q2YfYFtfbxMKbRcefK3VOeffbZqivt5ORkZs+ezahRo6ra07ds6YzF9dVXXzF37tyq46Kiok547kmTJhEY6Nyp5+bm8tvf/padO3ciIpSWllad99Zbb62qOqr8vGuvvZY33niDadOmsXLlSl5//fXT9BufPpYIPCVzp1P4b3gLCg9DZEcY+yAMvJp0jeSafy0nNiqQJycPdIaSNsacsq+//pqvvvqKlStXEhYWxujRoxk4cCDbtm1z+xzVm13W7CUdHn6sA+ef//xnzjvvPD788EP27dvH6NGj6z3vtGnTuOSSSwgJCWHSpEk++YwhwNsBnFFKi2Dje/DKL+F/E2HVC9D5F3Dth3D3BvjF7ygNi+HOt9aTX1TGC9cOoUWotQgy5ufKzc0lKiqKsLAwtm3bxnfffUdRURFLly5l7969AFVVQ+PHj2fWrFlVx1ZWDbVp04atW7dSUVFRbx1+bm4ucXFOQ45XX321av348eN58cUXKSsrO+7zYmNjiY2N5bHHHmPatGmn75c+jSwRnA4Z22HBTPhnL/jgRsg7AOMehnu3wuTXoesYCHC+6r9+to3v9x3miSsSnDGEjDE/24QJEygrK6N3797cf//9DB8+nNatWzN79mwuv/xyBgwYwJQpUwD405/+RHZ2Nv369WPAgAEsWbIEgCeeeIKLL76YESNG0K5duzo/67777uOBBx5g0KBBVYU+wI033kiHDh3o378/AwYM4K233qradvXVV9O+fXt69+7toW/g57FB534OVfjkblj3OgQEQ++LYch10GlUVcFf3fwfDnL32+u5bkQnHr7Ue3WpxpxOW7du9dkCzlfceeedDBo0iBtuuKFBPq+2fxMbdM5Tvp/tJIFht8Ko30N4dJ27bk89wh/mbSSxYxQzL7I/GmP8xZAhQwgPD+fJJ5/0dih1skRwqpK/hy9mQs9fOhPF1zO+R15RKbe+sZZmIUE8d/VgmgRZjZwx/mLt2rXeDuGErEQ6FfkZ8O5voUV7uOy5epNARYXyu3d/IPlwAbN+PZiYiJAGDNQYY07M7ghOVkU5vH+90yT0hoUQGlnv7s9/s5uFSWk8eHEfhna2OYWNMb7HEsHJWvLfsHcpTHwO2vWvd9dlOzN48svtXDIglmkjOzVMfMYYc5KsauhkbF8Ay56Ewb+FQVfXu2tKdgF3v72e7jHN+Z8rEmy8dmOMz7JE4K7De+HDm6HdALjwb/XuWlRazu1vrqOsXHn+msGENbEbL2OM77JE4I7SQnj3N4A4HcSC63/g+/D8LWxMyeXJyQPo0rpZw8RojHFLs2b2N1mTXaq647PfQ+pG+PW7ENWp3l3nfr+fuauTueO8rpzf12YVM37m8/shddPpPWfbBLjwidN7Th/gS3Mb2B3Biaz7D6z/j9NhrMcF9e66MSWHB+dv4Rfdo7l3fM8GCtAY/3b//fcfN3bQww8/zGOPPcbYsWMZPHgwCQkJfPzxx26dKz8/v87jXn/99arhI6699loA0tLS+NWvfsWAAQMYMGAAK1asYN++ffTr16/quH/84x88/PDDAIwePZp77rmHxMREnnnmGT755BOGDRvGoEGDGDduHGlpaVVxTJs2jYSEBPr378/777/PnDlzuOeee6rO+9JLLzFjxoxT/dqOp6qN6mfIkCHaYA5uUH00RvW1S1XLy+rdNSu/WEf8dZGO+OsizcovbqAAjfG+pKQkr37+unXrdNSoUVXLvXv31v3792tubq6qqmZkZGjXrl21oqJCVVXDw8PrPFdpaWmtx23evFm7d++uGRkZqqqalZWlqqqTJ0/Wp556SlVVy8rKNCcnR/fu3at9+/atOuff//53feihh1RV9dxzz9Xbbrutatvhw4er4nrppZf03nvvVVXV++67T6dPn37cfkeOHNEuXbpoSUmJqqqeffbZunHjxlp/j9r+TYA1Wke56hv3Jb6oMNt5LhDWCq74d72zhpVXKNPnricjv5h5t55Ny/AmDRioMf5t0KBBpKenc/DgQTIyMoiKiqJt27bMmDGDpUuXEhAQwIEDB0hLS6Nt2/qra1WVmTNn/uS4xYsXM2nSJKKjnWFkKucaWLx4cdX8AoGBgbRo0eKEE91UDn4HzoQ3U6ZM4dChQ5SUlFTNnVDXnAljxozh008/pXfv3pSWlpKQkHCS31btLBHUpqICPrwNcg/AtM/rHUMI4J8Lt7NsZyb/c0UC/eMjGyZGY0yVSZMmMW/ePFJTU5kyZQpvvvkmGRkZrF27luDgYDp16vSTOQZqc6rHVRcUFERFRUXVcn1zG9x1113ce++9XHrppXz99ddVVUh1ufHGG3n88cfp1avXaR3S2p4R1Obbp2DH53DB49D+rHp3XZiUxqwlu5l6VnumnNWhgQI0xlQ3ZcoU5s6dy7x585g0aRK5ubnExMQQHBzMkiVL+PHHH906T13HjRkzhvfee4+srCzg2FwDY8eO5fnnnwegvLyc3Nxc2rRpQ3p6OllZWRQXF/Ppp5/W+3mVcxu89tprVevrmjNh2LBhJCcn89Zbb3HVVVe5+/WckCWCmvZ8DYsfg35XwtCb6t1VVfnr51vp1ba5DSttjBf17duXI0eOEBcXR7t27bj66qtZs2YNCQkJvP766/Tq1cut89R1XN++ffnjH//Iueeey4ABA7j33nsBeOaZZ1iyZAkJCQkMGTKEpKQkgoODefDBBxk6dCjjx4+v97MffvhhJk2axJAhQ6qqnaDuORMAJk+ezMiRI92aYtNdNh9BdXkH4YVfOFVBNy6CpvW3N163P5vLn1vB367sz+TE9p6JyRgfZ/MRNKyLL76YGTNmMHbs2Dr3Odn5COyOoFJZiTOiaFkRTP7PCZMAwLy1KYQGB3JRQt2zGRljzOmQk5NDjx49CA0NrTcJnAp7WFxp4YOQ8j1c+Qq07nHC3YtKy/nkh4Nc2K8tzZra12hMY7Jp06aqvgCVmjZtyqpVq7wU0YlFRkayY8cOj5zbSjCAze/Dqudh+O3Q73K3DvkyKY0jRWVcOSTew8EZ4/tUtVENrJiQkMCGDRu8HYZHnEp1v1UNZWyHj++C9sNh/CNuHzZvbQpxkaEM79LKg8EZ4/tCQkLIyso6pQLInF6qSlZWFiEhJzcBln/fERTnwzvXQpMwmPQKBAa7dVhqbhHLd2Zw53ndCAhoPFdBxnhCfHw8KSkpZGRkeDsUg5OY4+NPrqbCfxOBKnxyN2TthGs/gohYtw/9YH0KFQpXWLWQMQQHB1f1iDWNk0erhkRkgohsF5FdInJ/LduvE5EMEdng+rnRk/Ec5/vZzrOBMX+GLue6fZiqMm9tCkM7taRjq/ATH2CMMT7OY3cEIhIIzALGAynAahGZr6pJNXZ9R1Xv9FQctUr+Hr6YCT0vgpH3nNSh65Nz2JNxlFtHdfVMbMYY08A8eUcwFNilqntUtQSYC0z04Oe5Jz/D6S/QIh4uex4CTu4rmLc2hZDgAC5MsLkGjDFnBk8+I4gDkqstpwDDatnvChEZBewAZqhqcs0dRORm4GbXYr6IbD/FmKKBzKqle069i3bEY6d86Mk4Pl7f1phihcYVb2OKFRpXvI0pVvh58Xasa4O3HxZ/ArytqsUicgvwGjCm5k6qOhuY/XM/TETW1NXF2hc1pngbU6zQuOJtTLFC44q3McUKnovXk1VDB4DqA/DEu9ZVUdUsVS12Lb4MDPFgPMYYY2rhyUSwGuguIp1FpAkwFZhffQcRqT5Iz6XAVg/GY4wxphYeqxpS1TIRuRP4AggE5qjqFhF5BGfKtPnA3SJyKVAGHAau81Q8Lj+7eqmBNaZ4G1Os0LjibUyxQuOKtzHFCh6Kt9ENQ22MMeb0srGGjDHGz1kiMMYYP+c3ieBEw134ChFpLyJLRCRJRLaIyHRvx+QOEQkUkfUiUvcErT5ARCJFZJ6IbBORrSJytrdjqo+IzHD9P9gsIm+LyMkNK+lhIjJHRNJFZHO1dS1FZKGI7HS9nr45FX+GOmL9u+v/wkYR+VBEIr0YYpXaYq227XcioiISXduxp8IvEkG14S4uBPoAV4lIH+9GVacy4Heq2gcYDtzhw7FWN53G0errGWCBqvYCBuDDMYtIHHA3kKiq/XAaXUz1blQ/8Sowoca6+4FFqtodWORa9gWv8tNYFwL9VLU/TqfWBxo6qDq8yk9jRUTaA+cD+0/nh/lFIsBXh7uohaoeUtV1rvdHcAqqOO9GVT8RiQd+idMXxGeJSAtgFPBvAFUtUdUcrwZ1YkFAqIgEAWHAQS/HcxxVXYrT4q+6iTidQ3G9XtaQMdWltlhV9UtVLXMtfofT38nr6vheAZ4C7gNOaysff0kEtQ134dOFK4CIdAIGAb47f57jaZz/nBVejuNEOgMZwCuuaqyXRcRnh5BV1QPAP3Cu/g4Buar6pXejcksbVT3kep8KtPFmMCfheuBzbwdRFxGZCBxQ1R9O97n9JRE0OiLSDHgfuEdV87wdT11E5GIgXVXXejsWNwQBg4HnVXUQcBTfqbb4CVfd+kScBBYLhIvINd6N6uSo0z7d59uoi8gfcapl3/R2LLURkTBgJvCgJ87vL4nghMNd+BIRCcZJAm+q6gfejucERgKXisg+nCq3MSLyhndDqlMKkKKqlXdY83ASg68aB+xV1QxVLQU+AEZ4OSZ3pFWOGuB6TfdyPPUSkeuAi4Gr1Xc7VnXFuSD4wfW3Fg+sE5HTMgyyvySCEw534SvEmQH838BWVf2nt+M5EVV9QFXjVbUTzve6WFV98qpVVVOBZBHp6Vo1Fqg5P4Yv2Q8MF5Ew1/+Lsfjww+1q5gO/db3/LfCxF2Opl4hMwKnWvFRVC7wdT11UdZOqxqhqJ9ffWgow2PV/+mfzi0TgehhUOdzFVuBdVd3i3ajqNBK4FufKunLmtou8HdQZ5C7gTRHZCAwEHvduOHVz3bnMA9YBm3D+Xn1qSAQReRtYCfQUkRQRuQF4AhgvIjtx7mqe8GaMleqI9X+B5sBC19/aC14N0qWOWD33eb57J2SMMaYh+MUdgTHGmLpZIjDGGD9nicAYY/ycJQJjjPFzlgiMMcbPWSIwpgYRKa/WdHfD6RytVkQ61TaipDHe5LGpKo1pxApVdaC3gzCmodgdgTFuEpF9IvI3EdkkIt+LSDfX+k4istg1pv0iEengWt/GNcb9D66fyuEhAkXkJdc8A1+KSKjXfiljsERgTG1Ca1QNTam2LVdVE3B6pD7tWvcv4DXXmPZvAs+61j8LfKOqA3DGNKrszd4dmKWqfYEc4AqP/jbGnID1LDamBhHJV9VmtazfB4xR1T2ugQFTVbWViGQC7VS11LX+kKpGi0gGEK+qxdXO0QlY6Jq0BRH5AxCsqo81wK9mTK3sjsCYk6N1vD8ZxdXel2PP6oyXWSIw5uRMqfa60vV+BcemkLwaWOZ6vwi4DarmdG7RUEEaczLsSsSYnwoVkQ3VlheoamUT0ijXyKXFwFWudXfhzHr2e5wZ0Ka51k8HZrtGjizHSQqHMMbH2DMCY9zkekaQqKqZ3o7FmNPJqoaMMcbP2R2BMcb4ObsjMMYYP2eJwBhj/JwlAmOM8XOWCIwxxs9ZIjDGGD/3/xmG4BrxS73DAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05FKU5ZF4thE"
      },
      "source": [
        "Как видно по результатам анализа глубокого обучения нейронной сети точность на обучающей группе составила 80%, а на тестовой не больше 70%"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}